{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Cho một list các số nguyên `num_list` và một `sliding window` (các bạn có thể tạm hiểu sliding window như là một list có kích thước nhỏ hơn `num_list`) có kích thước size k di chuyển từ trái\n",
    "sang phải. Mỗi lần dịch chuyển 1 vị trí sang phải có thể nhìn thấy đươc $k$ số trong `num_list` và tìm số lớn nhất trong k số này sau mỗi lần trượt. $k$ phải lớn hơn hoặc bằng 1. Các bạn hãy viết\n",
    "chương trình Python giải quyết vấn đề trên.\n",
    "\n",
    "* Input: `num_list = [3, 4, 5, 1, −44, 5, 10, 12, 33, 1]`, `k = 3`\n",
    "* Output: `[5, 5, 5, 5, 10, 12, 33, 33]`\n",
    "* Với input trên, quá trình tính toán của chương trình có thể được mô phỏng như sau (các bạn không nhất thiết phải code phần mô phỏng này):\n",
    "    * [3, 4, 5], 1, −44, 5, 10, 12, 33, 1 $\\implies$ max = 5\n",
    "    * 3, [4, 5, 1], −44, 5, 10, 12, 33, 1 $\\implies$ max = 5\n",
    "    * 3, 4, [5, 1, -44], 5, 10, 12, 33, 1 $\\implies$ max = 5\n",
    "    * 3, 4, 5, [1, -44, 5], 10, 12, 33, 1 $\\implies$ max = 5\n",
    "    * 3, 4, 5, 1, [-44, 5 , 10], 12, 33, 1 $\\implies$ max = 10\n",
    "    * 3, 4, 5, 1, −44, [5, 10, 12], 33, 1 $\\implies$ max = 12\n",
    "    * 3, 4, 5, 1, −44, 5, [10, 12, 33], 1 $\\implies$ max = 33\n",
    "    * 3, 4, 5, 1, −44, 5, 10, [12, 33, 1] $\\implies$ max = 33\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "# EXERCISE 1:\n",
    "#\n",
    "def find_largest_value_using_slide_window(num_list, k, *args, **kwargs):\n",
    "    assert (k >= 1), 'k must be greater or equal than 1!'\n",
    "    assert (k <= len(num_list)), 'k must be lesser or equal to the length of num_list!'\n",
    "\n",
    "    resulted_num_list = []\n",
    "    for idx, _ in enumerate(num_list):\n",
    "        ##\n",
    "        # 1. Generate sliding windows:\n",
    "        #\n",
    "        sliding_window = []\n",
    "        for jdx in range(k):\n",
    "            if (idx + jdx) >= (len(num_list)):\n",
    "                break\n",
    "            else:\n",
    "                sliding_window.append(num_list[idx + jdx])\n",
    "        \n",
    "        ##\n",
    "        # Sanity check:\n",
    "        #\n",
    "        # print(sliding_window)\n",
    "\n",
    "        ##\n",
    "        # 2. Find largest value within a sliding window\n",
    "        #\n",
    "        if (len(sliding_window) == k):\n",
    "            max_value = max(sliding_window)\n",
    "            resulted_num_list.append(max_value)\n",
    "\n",
    "    ##\n",
    "    # Sanity check:\n",
    "    # print(resulted_num_list)\n",
    "    \n",
    "    return resulted_num_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 5, 5, 5, 10, 12, 33, 33]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##\n",
    "# TEST:\n",
    "#\n",
    "num_list = [3, 4, 5, 1, -44, 5, 10, 12, 33, 1]\n",
    "k = 3\n",
    "find_largest_value_using_slide_window(num_list, k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Cho 2 list các số nguyên là `num_list1` và `num_list2`, các bạn hãy viết chương trình trả về list các số đều có trong 2 list đầu vào, thứ tự không quan trọng. Lưu ý, không được sử dụng hàm\n",
    "`intersection()` có sẵn của Python.\n",
    "* Case 1:\n",
    "    * Input: `nums1 = [1, 2, 2, 1]`, `nums2 = [2, 2]`\n",
    "    * Output: `[2, 2]`\n",
    "* Case 2:\n",
    "    * Input: `nums1 = [4, 9, 5]`, `nums2 = [9, 4, 9, 8, 4]`\n",
    "    * Output: `[4, 9]` hoặc `[9, 4]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "# EXERCISE 2:\n",
    "#\n",
    "def find_intersection_between_two_lists(num_list1, num_list2, *args, **kwargs):\n",
    "    length_numlist1 = len(num_list1)\n",
    "    length_numlist2 = len(num_list2)\n",
    "\n",
    "    intersection_list = []\n",
    "    if (length_numlist1 >= length_numlist2):\n",
    "        for _ , value in enumerate(num_list2):\n",
    "            if value in num_list1:\n",
    "                intersection_list.append(value)\n",
    "    else:\n",
    "        for _ , value in enumerate(num_list1):\n",
    "            if value in num_list2:\n",
    "                intersection_list.append(value)\n",
    "\n",
    "    return intersection_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 9]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##\n",
    "# TEST:\n",
    "#\n",
    "nums1 = [1, 2, 2, 1]\n",
    "nums2 = [2, 2]\n",
    "find_intersection_between_two_lists(nums1, nums2)\n",
    "\n",
    "nums1 = [4, 9, 5]\n",
    "nums2 = [9, 4, 9, 8, 4]\n",
    "find_intersection_between_two_lists(nums1, nums2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Cho các hàm toán học với công thức như sau:\n",
    "    * MAE = $\\frac{1}{n}\\sum^n_{i=1} |y_i − \\hat{y}_i|$\n",
    "    * MSE = $\\frac{1}{n}\\sum^n_{i=1} (y_i − \\hat{y}_i)^2$\n",
    "    * RMSE = $\\sqrt{MSE}$\n",
    "    * Huber Loss (với $\\delta = 0.5$) = $\\frac{1}{n}\\sum^n_{i=1} \\begin{cases} \\frac{1}{2} (y_i − \\hat{y}_i)^2, \\quad |y_i - \\hat{y}_i| \\leq \\delta \\\\ \\delta(|y_i - \\hat{y}_i| - \\frac{1}{2}\\delta ), \\quad |y_i - \\hat{y}_i| > \\delta \\end{cases}$\n",
    "\n",
    "Các công thức trên trong lĩnh vực Máy học (Machine Learning) còn được gọi là các hàm mất mát\n",
    "(Loss Function), các hàm này đóng vai trò như là một thước đo sự khác biệt giữa giá trị dự đoán\n",
    "của mô hình máy học so với giá trị thực tế của một mẫu dữ liệu (samples). Trong đó: $n$ là số\n",
    "lượng samples (`num_samples`), với $i(0 < i ≤ n)$ là thứ tự của mỗi sample cụ thể. Ở đây các\n",
    "bạn có thể hiểu là cứ mỗi $i$ thì sẽ có 1 cặp $y_i$ là target và $\\hat{y}_i$ là predict.\n",
    "\n",
    "Các bạn hãy viết chương trình Python với một số yêu cầu như sau:\n",
    "* Định nghĩa một hàm trả về 2 list $y$ (target) và $\\hat{y}$ (prediction). Mỗi list chứa số lượng các element bằng với num_sample và các element này dược tạo ngẫu nhiên trong khoảng [0, 10).\n",
    "* Input:\n",
    "    * Người dùng nhập số lượng sample (`num_samples`) được tạo ra (chỉ nhận integer numbers)\n",
    "    * Người dùng nhập loss name (`MAE`, `MSE`, `RMSE`, `Huber_Loss`)\n",
    "* Output: Print ra loss name và kết quả loss cuối cùng. Loss name là loss mà người dùng chọn.\n",
    "    * Phải kiểm tra `num_samples` có hợp lệ hay không (`num_samples` phải là số nguyên dương). Nếu không hợp lệ thì in ra màn hình một chuỗi `number of samples must be a postive integer number` và dừng chương trình.\n",
    "    * Phải kiểm tra tên của hàm mất mát có hợp lệ hay không (`MAE`, `MSE`, `RMSE`, `Huber_Loss`). Nếu không in ra màn hình một chuỗi `loss name loss is not supported`.\n",
    "    * Phải kiểm tra số lượng element của $y$ và $\\hat{y}$ có bằng nhau hay không? Và số lượng này có bằng `num_sample` hay không? Nếu không thì in ra màn hình một chuỗi `The number of samples is incorrect` và dừng chương trình.\n",
    "    * Khi đã qua các vòng check điều kiện, thực hiện tính giá trị hàm mất mát với 2 list $y$ và $\\hat{y}$ theo tên hàm mất mát người dùng nhập. Sau đó in tên của hàm mất mát đã chọn cùng kết quả trả về của hàm.\n",
    "    * Khi khởi tạo tự động xong $y$ và $\\hat{y}$ thì in kết quả ra màn hình như trong ví dụ ở code listing 1 (target cho $y$ và predict cho $\\hat{y}$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "# EXERCISE 3:\n",
    "#\n",
    "def mae(targets, predicts):\n",
    "    outputs = [abs(y - y_hat) for y, y_hat in zip(targets, predicts)]\n",
    "    outputs = sum(outputs) / len(outputs)\n",
    "    return outputs\n",
    "\n",
    "def mse(targets, predicts):\n",
    "    outputs = [(y - y_hat) ** 2 for y, y_hat in zip(targets, predicts)]\n",
    "    outputs = sum(outputs) / len(outputs)\n",
    "    return outputs\n",
    "\n",
    "def rmse(targets, predicts):\n",
    "    outputs = [(y - y_hat) ** 2 for y, y_hat in zip(targets, predicts)]\n",
    "    outputs = sum(outputs) / len(outputs)\n",
    "    outputs = math.sqrt(outputs)\n",
    "    return outputs\n",
    "\n",
    "def huber_loss(targets, predicts):\n",
    "    delta = 0.5\n",
    "    outputs = [(delta * (abs(y - y_hat) - 0.5 * delta)) if (abs(y - y_hat) > delta) else (0.5 * (y - y_hat) ** 2) for y, y_hat in zip(targets, predicts)]\n",
    "    return outputs\n",
    "\n",
    "loss_functions_dict = \\\n",
    "    {\n",
    "        'MAE': mae,\n",
    "        'MSE': mse,\n",
    "        'RMSE': rmse,\n",
    "        'Huber_loss' : huber_loss\n",
    "    }\n",
    "\n",
    "def compute_loss_function():\n",
    "    num_samples = int(input('Input number of samples (positive integer number) which are generated: '))\n",
    "    loss_name = input('Input loss name: ')\n",
    "\n",
    "    assert(num_samples > 0), 'Number of samples must be a postive integer number!'\n",
    "    assert(loss_name == 'MAE' or loss_name == 'MSE' or loss_name == 'RMSE' or loss_name == 'Huber_loss'), 'loss name loss is not supported'\n",
    "\n",
    "    targets = [random.uniform(0,10) for _ in range(num_samples)]\n",
    "    predicts = [random.uniform(0,10) for _ in range(num_samples)]\n",
    "    print(f'Targets: {targets}')\n",
    "    print(f'Predicts: {predicts}')\n",
    "    \n",
    "    loss_function = loss_functions_dict[loss_name]\n",
    "    outputs = loss_function(targets, predicts)\n",
    "    print(f'{loss_name}: outputs')\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targets: [0.8923078192559109, 3.120690937508165, 3.9203125440274578, 1.2676742447284928, 4.25071291059739]\n",
      "Predicts: [8.840124481014168, 8.854488341942831, 4.505407194192101, 7.300016660925515, 9.39288129541544]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5.0882439034745275"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##\n",
    "# TEST:\n",
    "#\n",
    "compute_loss_function()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Cho một số hàm toán học và đạo hàm của nó như sau:\n",
    " \n",
    "Các hàm trên trong lĩnh vực Học sâu (Deep Learning) còn được gọi là các Hàm kích hoạt (Activation Function), đóng vai trò rất quan trọng trong các kiến trúc mạng nơ-ron (Neural Network).\n",
    "Các bạn hãy thực hiện viết chương trình Python khai báo các hàm trên với một số yêu cầu sau:\n",
    "    * Xây dựng một hàm tổng hợp các hàm kích hoạt, cho phép lựa chọn hàm kích hoạt mong\n",
    "muốn thông qua tham số đầu vào và trả về giá trị hàm kích hoạt và giá trị đạo hàm của hàm\n",
    "kích hoạt tương ứng. Đồng thời, in ra hình ảnh vẽ trên đồ thị các kết quả trên. Hàm vẽ đồ\n",
    "thị sẽ được cài đặt như sau (các bạn cần tùy chỉnh lại tên biến sao cho phù hợp với code của\n",
    "mình):\n",
    "\n",
    "```\n",
    "import numpy as np\n",
    "import matplotlib . pyplot as plt\n",
    "\n",
    "def plot (data, output, output_derivative, activation_name):\n",
    "    x = np.array(list(sorted(data)))\n",
    "    y = np.array(list(sorted(output)))\n",
    "    y_derivative = np.array(list(sorted(output_derivative)))\n",
    "\n",
    "    ax = plt.gca()\n",
    "    ax.spines['top'].set_color('none')\n",
    "    ax.spines['left'].set_position('zero')\n",
    "    ax.spines['right'].set_color('none')\n",
    "    ax.spines['bottom'].set_position('zero')\n",
    "    plt.xlim(-np.pi, np.pi)\n",
    "    plt.plot(x, y, color = 'orange', label = activation_name)\n",
    "    plt.plot(x, y_derivative, color = 'green', label = f'{activation_name}_derivative')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    return None\n",
    "```\n",
    "\n",
    "* Input: Một list các số bất kì và tên hàm kích hoạt mong muốn sử dụng.\n",
    "* Output: Giá trị hàm kích hoạt, giá trị đạo hàm hàm kích hoạt và hình vẽ của kết quả\n",
    "trên trục tọa độ.\n",
    "\n",
    "Kết quả trả về mẫu (các bạn không nhất thiết phải làm giống với ví dụ mẫu, chỉ cần đảm\n",
    "bảo output yêu cầu):\n",
    "\n",
    "```\n",
    "data = [-2, -1, 0, 1, 2]\n",
    "exercise3(data , activation_name = 'sigmoid')\n",
    "\n",
    ">>>\n",
    "Activation function : sigmoid\n",
    "Original data : [-2, -1, 0, 1, 2]\n",
    "sigmoid(data) = [0.11920292202211757, 0.2689414213699951, 0.5, 0.7310585786300049, 0.8807970779778823]\n",
    "sigmoid_derivative(data) = [0.10499358540350653, 0.19661193324148185, 0.25 , 0.19661193324148185, 0.10499358540350662]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "# EXERCISE 4:\n",
    "#\n",
    "def tanh(x):\n",
    "    return 2 / (1 + math.exp(-2 * x)) - 1\n",
    "\n",
    "def derivative_tanh(x):\n",
    "    return 1 - (tanh(x)) ** 2\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + math.exp(-x))\n",
    "\n",
    "def derivative_sigmoid(x):\n",
    "    return sigmoid(x) * (1 - sigmoid(x))\n",
    "\n",
    "def ReLU(x):\n",
    "    if (x > 0):\n",
    "        return x\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def derivative_ReLU(x):\n",
    "    if (x > 0):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def PReLU(x, alpha = 0.25):\n",
    "    if (x > 0):\n",
    "        return x\n",
    "    else:\n",
    "        return alpha * x\n",
    "\n",
    "def derivative_PReLU(x, alpha = 0.25):\n",
    "    if (x > 0):\n",
    "        return 1\n",
    "    else:\n",
    "        return alpha\n",
    "\n",
    "def LeakyReLU(x, alpha = 0.01):\n",
    "    if (x > 0):\n",
    "        return x\n",
    "    else:\n",
    "        return alpha * 0.01\n",
    "\n",
    "def derivative_LeakyReLU(x, alpha = 0.01):\n",
    "    if (x > 0):\n",
    "        return 1\n",
    "    else:\n",
    "        return alpha\n",
    "\n",
    "def ELU(x, alpha = 0.01):\n",
    "    if (x > 0):\n",
    "        return x\n",
    "    else:\n",
    "        return alpha * (math.exp(x) - 1)\n",
    "\n",
    "def derivative_ELU(x, alpha = 0.01):\n",
    "    if (x > 0):\n",
    "        return 1\n",
    "    else:\n",
    "        return alpha * math.exp(x)\n",
    "\n",
    "def softplus(x):\n",
    "    return math.log(1 + math.exp(x))\n",
    "\n",
    "def derivative_softplus(x):\n",
    "    return 1 / (1 + math.exp(-x))\n",
    "\n",
    "def exponential(x):\n",
    "    return math.exp(x)\n",
    "\n",
    "def derivative_exponential(x):\n",
    "    return math.exp(x)\n",
    "\n",
    "def SELU(x, lmbda = 1.05, alpha = 1.67):\n",
    "    if (x > 0):\n",
    "        return lmbda * x\n",
    "    else:\n",
    "        return lmbda * (alpha * math.exp(x) - alpha)\n",
    "\n",
    "def derivative_SELU(x, lmbda = 1.05, alpha = 1.67):\n",
    "    if (x > 0):\n",
    "        return 1\n",
    "    else:\n",
    "        return lmbda * alpha * math.exp(x)\n",
    "\n",
    "def GELU(x):\n",
    "    c = 0.044715\n",
    "    return 0.5 * x * (1 + math.tanh(math.sqrt(2 / math.pi) * (x + c * x ** 3)))\n",
    "\n",
    "def derivative_GELU(x):\n",
    "    c1 = 0.0356774\n",
    "    c2 = 0.797885\n",
    "    c3 = 0.0535161\n",
    "    c4 = 0.398942\n",
    "    sech_x = 1 / math.cosh(c1 * x **3 + c2 * x)\n",
    "    return 0.5 * math.tanh(c1 * x ** 3 + c2 * x) + (c3 * x ** 3 + c4 * x) * (sech_x ** 2) + 0.5\n",
    "\n",
    "def hard_sigmoid(x):\n",
    "    if (x > 2.5):\n",
    "        return 1\n",
    "    elif (x <= 2.5) and (x >= -2.5):\n",
    "        return 0.2 * x + 0.5\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def derivative_hard_sigmoid(x):\n",
    "    if (x > 2.5):\n",
    "        return 0\n",
    "    elif (x <= 2.5) and (x >= -2.5):\n",
    "        return 0.2\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def softsign(x):\n",
    "    return x / (1 + abs(x))\n",
    "\n",
    "def derivative_softsign(x):\n",
    "    return x / ((1 + abs(x)) ** 2)\n",
    "\n",
    "def swish(x):\n",
    "    return x * (1 / (1 + math.exp(-x)))\n",
    "\n",
    "def derivative_swish(x):\n",
    "    return swish(x) + (1 / (1 + math.exp(-x))) * (1 - swish(x))\n",
    "\n",
    "activation_functions_dict= \\\n",
    "{\n",
    "    'tanh': tanh,\n",
    "    'sigmoid' : sigmoid,\n",
    "    'reLU' : ReLU,\n",
    "    'PreLU' : PReLU,\n",
    "    'LeakyReLU' : LeakyReLU,\n",
    "    'ELU' : ELU,\n",
    "    'softplus' : softplus,\n",
    "    'exponential' : exponential,\n",
    "    'SELU' : SELU,\n",
    "    'GELU' : GELU,\n",
    "    'hard_sigmoid' : hard_sigmoid,\n",
    "    'softsign' : softsign,\n",
    "    'swish' : swish\n",
    "}\n",
    "\n",
    "derivative_activation_functions_dict = \\\n",
    "{\n",
    "    'tanh': derivative_tanh,\n",
    "    'sigmoid' : derivative_sigmoid,\n",
    "    'reLU' : derivative_ReLU,\n",
    "    'PreLU' : derivative_PReLU,\n",
    "    'LeakyReLU' : derivative_LeakyReLU,\n",
    "    'ELU' : derivative_ELU,\n",
    "    'softplus' : derivative_softplus,\n",
    "    'exponential' : derivative_exponential,\n",
    "    'SELU' : derivative_SELU,\n",
    "    'GELU' : derivative_GELU,\n",
    "    'hard_sigmoid' : derivative_hard_sigmoid,\n",
    "    'softsign' : derivative_softsign,\n",
    "    'swish' : derivative_swish\n",
    "}\n",
    "\n",
    "def plot(data, output, output_derivative, activation_name):\n",
    "    x = np.array(list(sorted(data)))\n",
    "    y = np.array(list(sorted(output)))\n",
    "    y_derivative = np.array(list(sorted(output_derivative)))\n",
    "\n",
    "    ax = plt.gca()\n",
    "    ax.spines['top'].set_color('none')\n",
    "    ax.spines['left'].set_position('zero')\n",
    "    ax.spines['right'].set_color('none')\n",
    "    ax.spines['bottom'].set_position('zero')\n",
    "    plt.xlim(-np.pi, np.pi)\n",
    "    plt.plot(x, y, color = 'orange', label = activation_name)\n",
    "    plt.plot(x, y_derivative, color = 'green', label = f'{activation_name}_derivative')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def init_activation_function(data, activation_name, *args, **kwargs):\n",
    "    activation_function = activation_functions_dict[activation_name]\n",
    "    outputs = [activation_function(input_value) for input_value in data]\n",
    "    print(f'{activation_name}(data): {outputs}')\n",
    "\n",
    "    derivative_function = derivative_activation_functions_dict[activation_name]\n",
    "    outputs_derivative = [derivative_function(input_value) for input_value in data]\n",
    "    print(f'{activation_name}_derivative(data): {outputs}')\n",
    "\n",
    "\n",
    "    plot(data, outputs, outputs_derivative, activation_name)\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "# TEST\n",
    "#\n",
    "data = [-3, -2, -1, 0, 1, 2, 3]\n",
    "init_activation_function(data , activation_name = 'sigmoid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
